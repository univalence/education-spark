{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f1118e-c68e-44a0-b930-0ffa55e86538",
   "metadata": {},
   "source": [
    "# Introduction à Spark SQL\n",
    "\n",
    "Spark SQL est un module d'Apache Spark, qui facilite la mise en place de traitement sur des données à haute volumétrie :\n",
    " * **structurées** : la donnée est stockée sous un format standardisé (CSV, JSON, Avro, Parquet...) et répond à une structure partagée (ie. schéma) répondant à un besoin technique ou métier\n",
    " * **semi-structurées** : la donnée est stockée sous un format standardisé, mais sa structure interne n'est pas connue par avance.\n",
    "\n",
    "Spark SQL offre une interface pour interagir avec les données via le langage SQL, ainsi que des fonctionnalités pour la lecture et l'écriture de données dans divers formats. Spark SQL facilite l'intégration entre le traitement des données relationnelles et le traitement distribué à grande échelle en utilisant les DataFrames et les Datasets, deux structures de données immuables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19baddc0-a3fe-468b-b2cc-958e9c435b9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Préambule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37318b58-9804-4a27-a375-5fffe4ed62a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-core:3.3.2`\n",
    "import $ivy.`org.apache.spark::spark-sql:3.3.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2611e135-c2c4-4056-a972-c98e16e7095c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling /home/jovyan/work/internal/spark_helper.scLoading spark-stubs\n",
      "Getting spark JARs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: No SLF4J providers were found.\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://9bf93c2808c6:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.rdd._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@33adb981\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\n",
       "// Ce script fournit que élément supplémentaires pour rendre l'affichage plus confortable\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$                      , spark_helper._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Avoid disturbing logs\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.rdd._\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    // L'appel ci-dessous sert à donner un nom à votre application\n",
    "    // Ce apparaîtra notamment dans la Spark UI\n",
    "    .appName(\"Sales Analysis - SparkSQL\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "// Ce script fournit que élément supplémentaires pour rendre l'affichage plus confortable\n",
    "import $file.^.internal.spark_helper, spark_helper._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca8a53-5f83-49eb-aa1c-6cfca43b1d27",
   "metadata": {},
   "source": [
    "## Lecture d'un fichier avec Spark SQL\n",
    "\n",
    "Nous allons récupérer le fichier `orders.csv` et réaliser des analyses sur ce fichier.\n",
    "\n",
    "Commençons par afficher un extrait de son contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d149965-e818-401a-a0df-e215bfcf491a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <pre style=\"background: black; color: lightgray; padding: 1ex\">\n",
       "<span style=\"color: cyan\">/home/jovyan/work/02_spark_sql $</span> <span style=\"color: white\">cat orders.csv</span>\n",
       "id,client,timestamp,product,price\n",
       "87365481,XztHU0aeUckvR7AC,2022-11-14T13:25:36,café allongé,1.4\n",
       "42761208,t_CUBr6tyTQxGj2X,2022-11-14T13:29:46,café crème,2.5\n",
       "90524048,hdVMQjoIgOov09zb,2022-11-14T13:34:09,chocolat chaud,2.6\n",
       "09935741,hdVMQjoIgOov09zb,2022-11-14T13:37:10,chocolat chaud,2.6\n",
       "03486136,TX7wC0pTqCRlCOhi,2022-11-14T13:40:52,expresso,1.1\n",
       "46727424,H-Mp22FLe99MNhRa,2022-11-14T13:45:13,décaféiné,1.4\n",
       "97190478,oplTx8h-38G3be4c,2022-11-14T13:50:05,décaféiné,1.4\n",
       "49642764,TX7wC0pTqCRlCOhi,2022-11-14T13:53:27,expresso,1.1\n",
       "33866371,JBoCs7rWb_jEs87W,2022-11-14T13:56:58,double café,2.6</pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shell(\"cat orders.csv\", limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500bdcd5-ca8b-4927-b5a6-18ef5e14bee8",
   "metadata": {},
   "source": [
    "### Lecture : première approche\n",
    "La récupération du contenu d'un fichier avec Spark SQL va s'avérer beaucoup plus simple qu'avec Spark Core, car Spark SQL est fourni avec un ensemble de codec pour gérer les formats CSV, JSON, texte, binaire, Avro, Parquet, ORC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914c0edb-9968-4c69-963f-696d694e4069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">csv at cmd6.sc:9</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">csv at cmd6.sc:9</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">showHTML</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <table class=\"table\">\n",
       "        <tr>\n",
       "        <th>id</th><th>client</th><th>timestamp</th><th>product</th><th>price</th>\n",
       "        </tr>\n",
       "        <tr><td>87365481</td><td>XztHU0aeUckvR7AC</td><td>2022-11-14 13:25:36.0</td><td>café allongé</td><td>1.4</td></tr><tr><td>42761208</td><td>t_CUBr6tyTQxGj2X</td><td>2022-11-14 13:29:46.0</td><td>café crème</td><td>2.5</td></tr><tr><td>90524048</td><td>hdVMQjoIgOov09zb</td><td>2022-11-14 13:34:09.0</td><td>chocolat chaud</td><td>2.6</td></tr><tr><td>9935741</td><td>hdVMQjoIgOov09zb</td><td>2022-11-14 13:37:10.0</td><td>chocolat chaud</td><td>2.6</td></tr><tr><td>3486136</td><td>TX7wC0pTqCRlCOhi</td><td>2022-11-14 13:40:52.0</td><td>expresso</td><td>1.1</td></tr><tr><td>46727424</td><td>H-Mp22FLe99MNhRa</td><td>2022-11-14 13:45:13.0</td><td>décaféiné</td><td>1.4</td></tr><tr><td>97190478</td><td>oplTx8h-38G3be4c</td><td>2022-11-14 13:50:05.0</td><td>décaféiné</td><td>1.4</td></tr><tr><td>49642764</td><td>TX7wC0pTqCRlCOhi</td><td>2022-11-14 13:53:27.0</td><td>expresso</td><td>1.1</td></tr><tr><td>33866371</td><td>JBoCs7rWb_jEs87W</td><td>2022-11-14 13:56:58.0</td><td>double café</td><td>2.6</td></tr><tr><td>55962364</td><td>t_CUBr6tyTQxGj2X</td><td>2022-11-14 16:00:30.0</td><td>expresso</td><td>1.1</td></tr>\n",
       "      </table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataframe\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id: int, client: string ... 3 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataframe: DataFrame =\n",
    "  spark.read\n",
    "    // indique que le fichier contient une ligne d'en-tête qui servira\n",
    "    // pour nommer les champs\n",
    "    .option(\"header\", true)\n",
    "    // demande à Spark SQL de tenter de déterminer le type des colonnes\n",
    "    .option(\"inferSchema\", true)\n",
    "    // lecture du fichier au format CSV\n",
    "    .csv(\"orders.csv\")\n",
    "\n",
    "dataframe.showHTML(limit=10,truncate=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116c4fd-ad87-44a9-978a-ed0c3a9a3517",
   "metadata": {},
   "source": [
    "**Ce qu'il faut voir**\n",
    "\n",
    "Dans la Spark UI, vous pouvez voir un nouvel onglet dans la barre du haut intitulé \"SQL / DataFrame\". En cliquant dessus, vous verrez apparaître les requêtes exécutées par Spark SQL. Si vous cliquez sur une requête, vous verrez un diagramme représentant le plan d'exécution et dans la partie \"Details\" une représentation textuelle du plan d'exécution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dbc2e0-b274-4b8b-b4d5-d79fabad1969",
   "metadata": {},
   "source": [
    "Affichons le schéma de notre dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99870fe4-99ad-4c27-a869-b0905c5a4650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- client: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae43160-2d64-4a69-b5fc-ed91ef3a66e0",
   "metadata": {},
   "source": [
    "**Ce qu'il faut voir**\n",
    "\n",
    "Avec l'instruction `dataframe.printSchema`, nous pouvons voir que Spark a réussi à déterminer le schéma des données du fichier. Ce qui inclut le fait de déterminer le nom des colonnes et de déterminer le type des colonnes (grâce à l'option `inferSchema` pour ce dernier). Cependant, l'option `inferSchema` a deux problèmes majeurs :\n",
    "\n",
    " * Il nécessite une lecture supplémentaire du fichier (sur un extrait). Si vous regardez dans le Spark UI, vous verrez deux étapes de lecture CSV.\n",
    " * Il peut se tromper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592403e-0275-45a7-971e-6663888a81bb",
   "metadata": {},
   "source": [
    "### Lecture : deuxième approche\n",
    "Nous allons maintenant relire le fichier CSV, mais cette fois en fournissant directement un schéma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84fafa1-5a6e-4b0c-b27b-131f61d096a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-b6387fd3-ed76-4204-98cf-650037c30173', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">showHTML</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <table class=\"table\">\n",
       "        <tr>\n",
       "        <th>id</th><th>client</th><th>timestamp</th><th>product</th><th>price</th>\n",
       "        </tr>\n",
       "        <tr><td>87365481</td><td>XztHU0aeUckvR7AC</td><td>2022-11-14 13:25:36.0</td><td>café allongé</td><td>1.4</td></tr><tr><td>42761208</td><td>t_CUBr6tyTQxGj2X</td><td>2022-11-14 13:29:46.0</td><td>café crème</td><td>2.5</td></tr><tr><td>90524048</td><td>hdVMQjoIgOov09zb</td><td>2022-11-14 13:34:09.0</td><td>chocolat chaud</td><td>2.6</td></tr><tr><td>09935741</td><td>hdVMQjoIgOov09zb</td><td>2022-11-14 13:37:10.0</td><td>chocolat chaud</td><td>2.6</td></tr><tr><td>03486136</td><td>TX7wC0pTqCRlCOhi</td><td>2022-11-14 13:40:52.0</td><td>expresso</td><td>1.1</td></tr><tr><td>46727424</td><td>H-Mp22FLe99MNhRa</td><td>2022-11-14 13:45:13.0</td><td>décaféiné</td><td>1.4</td></tr><tr><td>97190478</td><td>oplTx8h-38G3be4c</td><td>2022-11-14 13:50:05.0</td><td>décaféiné</td><td>1.4</td></tr><tr><td>49642764</td><td>TX7wC0pTqCRlCOhi</td><td>2022-11-14 13:53:27.0</td><td>expresso</td><td>1.1</td></tr><tr><td>33866371</td><td>JBoCs7rWb_jEs87W</td><td>2022-11-14 13:56:58.0</td><td>double café</td><td>2.6</td></tr><tr><td>55962364</td><td>t_CUBr6tyTQxGj2X</td><td>2022-11-14 16:00:30.0</td><td>expresso</td><td>1.1</td></tr>\n",
       "      </table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataframe\u001b[39m: \u001b[32mDataFrame\u001b[39m = [id: string, client: string ... 3 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataframe: DataFrame =\n",
    "  spark.read\n",
    "    // indique que le fichier contient une ligne d'en-tête qui servira\n",
    "    // pour nommer les champs\n",
    "    .option(\"header\", true)\n",
    "    // force le schéma\n",
    "    .schema(\"id STRING, client STRING, timestamp TIMESTAMP, product STRING, price DOUBLE\")\n",
    "    // lecture du fichier au format CSV\n",
    "    .csv(\"orders.csv\")\n",
    "\n",
    "dataframe.showHTML(limit=10,truncate=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a289858-9634-41d9-ac61-94534c255b37",
   "metadata": {},
   "source": [
    "**Ce qu'il faut voir**\n",
    "\n",
    "Le fait de fournir un schéma va inciter Spark SQL à ne pas réaliser des analyses préalables ou des vérifications. Nous voyons, en effet, que l'ensemble du process est réduit à un job au lieu de trois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65dd0a10-f7e7-4e92-b0fa-c5ebbe68416c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">showHTML</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <table class=\"table\">\n",
       "        <tr>\n",
       "        <th>id</th><th>clientId</th><th>timestamp</th><th>product</th><th>price</th>\n",
       "        </tr>\n",
       "        <tr><td>87365481</td><td>XztHU0aeUckvR7AC</td><td>2022-11-14 13:25:36.0</td><td>café allongé</td><td>1.4</td></tr><tr><td>42761208</td><td>t_CUBr6tyTQxGj2X</td><td>2022-11-14 13:29:46.0</td><td>café crème</td><td>2.5</td></tr><tr><td>90524048</td><td>hdVMQjoIgOov09zb</td><td>2022-11-14 13:34:09.0</td><td>chocolat chaud</td><td>2.6</td></tr><tr><td>09935741</td><td>hdVMQjoIgOov09zb</td><td>2022-11-14 13:37:10.0</td><td>chocolat chaud</td><td>2.6</td></tr><tr><td>03486136</td><td>TX7wC0pTqCRlCOhi</td><td>2022-11-14 13:40:52.0</td><td>expresso</td><td>1.1</td></tr><tr><td>46727424</td><td>H-Mp22FLe99MNhRa</td><td>2022-11-14 13:45:13.0</td><td>décaféiné</td><td>1.4</td></tr><tr><td>97190478</td><td>oplTx8h-38G3be4c</td><td>2022-11-14 13:50:05.0</td><td>décaféiné</td><td>1.4</td></tr><tr><td>49642764</td><td>TX7wC0pTqCRlCOhi</td><td>2022-11-14 13:53:27.0</td><td>expresso</td><td>1.1</td></tr><tr><td>33866371</td><td>JBoCs7rWb_jEs87W</td><td>2022-11-14 13:56:58.0</td><td>double café</td><td>2.6</td></tr><tr><td>55962364</td><td>t_CUBr6tyTQxGj2X</td><td>2022-11-14 16:00:30.0</td><td>expresso</td><td>1.1</td></tr>\n",
       "      </table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.sql.Timestamp\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mOrder\u001b[39m\n",
       "\u001b[36morders\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mOrder\u001b[39m] = [id: string, clientId: string ... 3 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.sql.Timestamp\n",
    "\n",
    "case class Order(\n",
    "  id:        String,\n",
    "  clientId:  String,\n",
    "  timestamp: Timestamp,\n",
    "  product:   String,\n",
    "  price:     Double\n",
    ")\n",
    "\n",
    "val orders: Dataset[Order] =\n",
    "  dataframe\n",
    "    .withColumnRenamed(\"client\", \"clientId\")\n",
    "    .as[Order]\n",
    "\n",
    "orders.showHTML(limit=10, truncate=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75afb3d-9848-4cb8-b26b-d23940e73991",
   "metadata": {},
   "source": [
    "## Trouvez le produit le plus vendu (ID du produit et quantité totale vendue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cbd36b-ed57-428c-9a09-5363ef3a2636",
   "metadata": {},
   "source": [
    "### Première approche : utilisation de l'API Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e37da0-c7a9-404d-bbbc-e9ebe603205e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">showHTML</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">showHTML</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <table class=\"table\">\n",
       "        <tr>\n",
       "        <th>product</th><th>count</th>\n",
       "        </tr>\n",
       "        <tr><td>expresso</td><td>3215</td></tr><tr><td>café</td><td>1804</td></tr><tr><td>café allongé</td><td>1301</td></tr><tr><td>décaféiné</td><td>1004</td></tr><tr><td>noisette</td><td>798</td></tr><tr><td>café crème</td><td>728</td></tr><tr><td>chocolat chaud</td><td>604</td></tr><tr><td>double café</td><td>546</td></tr>\n",
       "      </table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orders\n",
    "  .groupBy($\"product\")\n",
    "  .agg(count(lit(1)).as(\"count\"))\n",
    "  .orderBy($\"count\".desc)\n",
    "  .showHTML()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a861cbd-6207-4bb7-bddc-9153b73ec4eb",
   "metadata": {},
   "source": [
    "### Deuxième approche : utilisation d'une requête SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37416028-01fc-4cff-b396-f0c35804a9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">showHTML</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">showHTML</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <table class=\"table\">\n",
       "        <tr>\n",
       "        <th>product</th><th>count</th>\n",
       "        </tr>\n",
       "        <tr><td>expresso</td><td>3215</td></tr><tr><td>café</td><td>1804</td></tr><tr><td>café allongé</td><td>1301</td></tr><tr><td>décaféiné</td><td>1004</td></tr><tr><td>noisette</td><td>798</td></tr><tr><td>café crème</td><td>728</td></tr><tr><td>chocolat chaud</td><td>604</td></tr><tr><td>double café</td><td>546</td></tr>\n",
       "      </table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orders.createTempView(\"orders\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT product, count(1) as count\n",
    "FROM orders\n",
    "GROUP BY product\n",
    "ORDER BY count DESC\n",
    "\"\"\").showHTML()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca6bfb9-a1f1-47b3-8cfb-bd7ec36e09d5",
   "metadata": {},
   "source": [
    "**Ce qu'il faut voir**\n",
    "\n",
    "Si vous regardez le plan d'exécution de cette requête et que vous le comparez au plan d'exécution obtenu à travers l'utilisation de l'API Spark SQL, vous remarquerez que ces deux plans d'exécution sont identiques. Ce qui indique bien que les deux approches font exactement la même chose et qu'elles le font avec les mêmes performances.\n",
    "\n",
    "Ainsi, Spark SQL vous donne la possibilité d'utiliser le langage qui vous convient le plus, tout en ayant le même comportement de la part de Spark. Ceci est vrai dans la majorité des cas, si vous vous tenez aux fonctions de base fournies par Spark SQL. C'est moins vrai dès que vous introduisez des éléments personnalisés (eg. UDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf9d8d-faa7-4ffd-a935-2e73d4c93896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
