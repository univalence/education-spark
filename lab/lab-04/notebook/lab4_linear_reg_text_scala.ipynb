{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed computation\n",
    "## ESIPE — INFO 3 — Option Logiciel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:35px;font-weight: bold;\">Lab 4 : Songs release year prediction </p>\n",
    "\n",
    " This lab covers a common supervised learning pipeline, using a subset of the [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Our goal is to train a linear regression model to predict the release year of a song given a set of audio features.\n",
    " \n",
    " Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Scala API](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.package)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20pt; font-weight: bold;color:blue\"> How to complete this lab :</p>\n",
    "\n",
    "This assignment is broken up into sections with bite-sized examples for demonstrating Spark functionality for log processing. For each problem, you should start by thinking about the algorithm that you will use to *efficiently* process the log in a parallel, distributed manner. This means using the various [RDD](https://spark.apache.org/docs/2.4.8/api/scala/index.html#org.apache.spark.rdd.RDD) operations along with [`anonymous` functions](https://docs.scala-lang.org/scala3/book/fun-anonymous-functions.html) that are applied at each worker.\n",
    "\n",
    " \n",
    "This assignment consists of 3 parts:\n",
    "\n",
    "- Part 1: Exploring the initial dataset with Spark Core.\n",
    "- Part 2: Machine learning with Spark MLlib.\n",
    "- Part 3: Beat the benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Prerequisites : Spark Context configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//using spark 2.4.8 because vegas plot library only works with scala 2.11\n",
    "import $ivy.`org.apache.spark::spark-sql:2.4.8`\n",
    "\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "\n",
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = SparkSession.builder\n",
    "  .appName(\"lab4_linear_reg_text\")\n",
    "  .master(\"local[*]\")\n",
    "  //.config(\"spark.executor.memory\", \"8g\")\n",
    "  //.config(\"spark.driver.memory\", \"8g\")\n",
    "  .getOrCreate()\n",
    "val sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Exploring the initial dataset with Spark Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Load and check the data\n",
    "\n",
    " The raw data is currently stored in text file.  We will start by storing this raw data in as an RDD, with each element of the RDD representing a data point as a comma-delimited string. Each string starts with the label (a year) followed by numerical audio features. Load the data into a two partitions RDD using SparkContext. Then Use the [count method](https://spark.apache.org/docs/2.4.8/api/scala/index.html#org.apache.spark.rdd.RDD@count():Long) to check how many data points we have.  Finally use the [take method](https://spark.apache.org/docs/2.4.8/api/scala/index.html#org.apache.spark.rdd.RDD@take(num:Int):Array[T]) to create and print out a list of the first 5 data points in their initial string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// declaring testing function\n",
    "def assertEquals[A](expected : A, answer : A, error : String) = {\n",
    "    if (expected equals answer) println(\"1 test passed\")\n",
    "    else error\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fileName = \"../resources/tp2/millionsong.txt\" //change path to where the file is if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "val numPartitions = 2\n",
    "val rawData: RDD[String] = ???\n",
    "\n",
    "val numPoints: Long = ???\n",
    "println( numPoints )\n",
    "\n",
    "val samplePoints: Array[String] = ???\n",
    "println( samplePoints )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Load and check the data (1.1)\n",
    "assertEquals(numPoints, 6724, \"incorrect value for numPoints\")\n",
    "assertEquals(samplePoints.length, 5, \"incorrect length for samplePoints\")\n",
    "assertEquals(rawData.getNumPartitions, 2, \"Incorrect number of partitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parsing the rows \n",
    "\n",
    "As you can see using methods `collect`or `take`, the `rawData` RDD only contains string elements that cannot be used for Data exploration or machine learning. Define a function `row_parser` you can use into a `map` method in order to parse the rows. Make sure all defined elements are casted as float elements. Assign the parsed RDD to variable `parsed_rdd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "\n",
    "???\n",
    "      \n",
    "val parsed_rdd: RDD[Array[Float]] = ???\n",
    "val parsed_rdd_sample: Array[Array[Float]] = parsed_rdd.take(5)\n",
    "parsed_rdd_sample.foreach(x => println(x.mkString(\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Parsing the rows (1.2)\n",
    "val round_sample_0: List[Double] = parsed_rdd_sample(0).map(x => (x*10.0).round/10.0).toList\n",
    "assertEquals(parsed_rdd_sample(0).length, 13, \"incorrect number of elements\")\n",
    "assertEquals(round_sample_0, List(2001.0, 0.9, 0.6, 0.6, 0.5, 0.2, 0.4, 0.3, 0.3, 0.6, 0.4, 0.6, 0.4), \"Incorrect parsing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Take a first look to the features\n",
    "\n",
    "Let's take a first look to the dataset features.  First we will look at the raw features for 50 data points by generating a heatmap that visualizes each feature on a grey-scale and shows the variation of each feature across the 50 sample data points.  The features are all between 0 and 1, with values closer to 1 represented via darker shades of grey. To achieve this task, extract the first 50 observations features and assign the result to variable `top_50_features`.\n",
    "\n",
    "_Note_ : More advanced features description will be provided in part 2 using Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "val top_50_features =  parsed_rdd.???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Take a first look to the featrues (1.3)\n",
    "assertEquals(top_50_features.length, 50, \"incorrect number of rows\")\n",
    "assertEquals(top_50_features(0).map(x => (x*100.0).round/100.0).toList, List(0.88, 0.61, 0.6, 0.47, 0.25, 0.36, 0.34, 0.34, 0.6, 0.43, 0.6, 0.42), \"Values don't match.\")\n",
    "assertEquals(top_50_features.map(_.length).toSet, Set(12), \"incorrect number of features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.vegas-viz::vegas:0.3.11`\n",
    "import $ivy.`org.vegas-viz::vegas-spark:0.3.11`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vegas._\n",
    "import vegas.sparkExt._\n",
    "\n",
    "Vegas(\"Year Releases\").\n",
    "  mark(Point).\n",
    "  //withData(year_release_keys.zip(year_release_values).map(x => Map(\"Year\"->x._1,\"Count\"->x._2))).\n",
    "  withData(top_50_features\n",
    "           .map(x => x.zipWithIndex).zipWithIndex\n",
    "           .flatMap(y => y._1.map(z => (z._1,y._2,z._2)))\n",
    "           .map(x => Map(\"Row\"->x._2,\"Column\"->x._3,\"Feature\"->x._1))\n",
    "           ).\n",
    "  encodeX(\"Column\", Ord, axis=Axis(title=\"Feature\")).\n",
    "  encodeY(\"Row\", Ord, scale=Scale(bandSize = 8.0), axis=Axis(title=\"Observation\")).\n",
    "  encodeColor(\"Feature\", Quant, scale=Scale(rangeNominals=List(\"#DDDDDD\", \"#000000\"))).\n",
    "  show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Describe year release label with Spark Core\n",
    "\n",
    "Get more information on the `year release` variable to predict. Extract the release years, compute the `min`, the `max`, the `mean` and plot a resulting histogram. Don't forget to `reduceByKey` before collect and assign the results to the following variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "val year_release_rdd: RDD[Float] = parsed_rdd.???\n",
    "val year_release_min: Float = ???\n",
    "val year_release_max: Float = ???\n",
    "val year_release_mean: Double = ???\n",
    "\n",
    "// Count the number of occurence for each year\n",
    "val year_release_count: Array[(Float, Int)] = ???\n",
    "\n",
    "// Year\n",
    "val year_release_keys: Array[Float] = ???\n",
    "\n",
    "// Number of occurence\n",
    "val year_release_values: Array[Int] = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Describe year release (1.4)\n",
    "assertEquals(year_release_min, 1922.0, \"incorrect minimum\")\n",
    "assertEquals(year_release_max, 2011.0, \"incorrect maximum\")\n",
    "assertEquals((year_release_mean*10).round/10.0, 1975.8, \"incorrect mean\")\n",
    "assertEquals(year_release_keys.toList.sorted, List(2008.0, 2002.0, 2004.0, 1992.0, 2000.0, 1996.0, 1998.0, 2006.0, 1930.0, 1990.0, 1994.0, 1974.0, 1976.0, 1970.0, 1972.0, 2010.0, 1988.0, 1980.0, 1986.0, 1958.0, 1978.0, 1968.0, 1962.0, 1982.0, 1984.0, 1966.0, 1964.0, 1960.0, 1942.0, 1926.0, 1956.0, 1954.0, 1928.0, 1948.0, 1922.0, 1952.0, 1944.0, 1946.0, 1950.0, 1932.0, 1938.0, 1936.0, 1940.0, 1934.0, 1924.0, 2001.0, 2007.0, 2003.0, 1999.0, 1997.0, 1987.0, 2005.0, 2009.0, 1993.0, 1991.0, 1933.0, 1935.0, 1995.0, 1941.0, 1943.0, 1975.0, 1971.0, 1981.0, 1989.0, 1969.0, 1973.0, 1983.0, 1985.0, 1979.0, 1967.0, 1961.0, 1965.0, 1963.0, 1977.0, 1945.0, 1955.0, 1927.0, 1957.0, 1959.0, 1953.0, 1949.0, 1939.0, 1937.0, 1951.0, 1929.0, 1947.0, 1931.0, 1925.0, 2011.0).sorted, \"incorrect bar plot x-label\")\n",
    "assertEquals(year_release_values.toList.sorted, List(100, 100, 100, 100, 100, 100, 100, 100, 38, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 21, 19, 100, 100, 48, 38, 6, 65, 14, 29, 58, 11, 19, 22, 14, 28, 5, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 6, 24, 100, 31, 13, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 27, 100, 40, 100, 100, 100, 53, 35, 25, 62, 79, 55, 31, 7, 1).sorted, \"incorrect bar plot y-label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// plotting the histogram :\n",
    "import vegas._\n",
    "import vegas.sparkExt._\n",
    "\n",
    "Vegas(\"Year Releases\", width = 1000).\n",
    "  mark(Bar).\n",
    "  withData(year_release_keys.zip(year_release_values).map(x => Map(\"Year\"->x._1,\"Count\"->x._2))).\n",
    "  encodeX(\"Year\", Nom).\n",
    "  encodeY(\"Count\", Quant).\n",
    "  show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Shift the labels\n",
    "\n",
    "As we just saw, the labels are years in the 1900s and 2000s.  In learning problems, it is often natural to shift labels such that they start from zero.  Starting with `parsed_rdd`, create a new RDD into which the labels are shifted such that smallest label equals zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "val parsed_rdd_shift: RDD[Array[Float]] = parsed_rdd.???\n",
    "//parsed_rdd_shift.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Shift labels (1.5)\n",
    "val old_features: Array[Array[Float]] = parsed_rdd.map(row => row.tail).take(5)\n",
    "val new_features: Array[Array[Float]] = parsed_rdd_shift.map(row => row.tail).take(5)\n",
    "val min_year_new: Float = parsed_rdd_shift.map(row => row(0)).min()\n",
    "val max_year_new: Float = parsed_rdd_shift.map(row => row(0)).max()\n",
    "assertEquals(old_features.map(_.toList).toList, new_features.map(_.toList).toList, \"new features do not match old features\")\n",
    "assertEquals(min_year_new, 0.0, \"incorrect min year in shifted data\")\n",
    "assertEquals(max_year_new, 89.0, \"incorrect max year in shifted data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 : Machine learning with Spark MLlib\n",
    "\n",
    "Now, we will perform machine learning with  Spark’s machine learning (ML) library,with the DataFrame-based API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create dataframe\n",
    "\n",
    "Using RDD `parsed_rdd_shift` from part 1, create a Spark SQL dataframe called `ml_df`.\n",
    "- Check that columns casting are all float or double.\n",
    "- Check that the label column is named 'year_release' and the features like (feature_0, feature_1, ..., feature_11).\n",
    "- Make sure to cache the dataframe in order to improve your following performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-mllib:2.4.8`\n",
    "\n",
    "// TODO: Replace <FILL IN> with appropriate code\n",
    "val label = \"year_release\"\n",
    "val features = Range(0, 12).map(num => s\"feature_${num}\")\n",
    "\n",
    "val spark = SparkSession.builder\n",
    "  .appName(\"lab4_linear_reg_text\")\n",
    "  .master(\"local[*]\")\n",
    "  .config(\"spark.executor.memory\", \"8g\")\n",
    "  .config(\"spark.driver.memory\", \"8g\")\n",
    "  .getOrCreate()\n",
    "val sc = spark.sparkContext\n",
    "\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val schema: StructType = ???\n",
    "\n",
    "val ml_df: DataFrame = ???\n",
    "ml_df.printSchema()\n",
    "ml_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Create dataframe (3.1)\n",
    "assertEquals(ml_df.getClass.toString, \"class org.apache.spark.sql.Dataset\", \"ml_df is not a Spark DataFrame.\")\n",
    "assertEquals(ml_df.storageLevel.useMemory, true, \"dataframe has to be cached\")\n",
    "assertEquals(ml_df.dtypes.toList, List((\"year_release\", \"DoubleType\"), (\"feature_0\", \"DoubleType\"), (\"feature_1\", \"DoubleType\"), (\"feature_2\", \"DoubleType\"), (\"feature_3\", \"DoubleType\"), (\"feature_4\", \"DoubleType\"), (\"feature_5\", \"DoubleType\"), (\"feature_6\", \"DoubleType\"), (\"feature_7\", \"DoubleType\"), (\"feature_8\", \"DoubleType\"), (\"feature_9\", \"DoubleType\"), (\"feature_10\", \"DoubleType\"), (\"feature_11\", \"DoubleType\")), \"Dataframe schema is not correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train, validation, test Split \n",
    "\n",
    "Such as earlier, search for method `randomSplit` from `spark.sql` module and make a train-val-test split with associated proportions `[0.8, 0.1, 0.1]`. \n",
    "- Assign the training dataframe to variable train_df.\n",
    "- Assign the validation dataframe to variable val_df.\n",
    "- Assign the test dataframe to variable test_df.\n",
    "- Make sure to cache all these dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "val weights: Array[Double] = Array(.8, .1, .1)\n",
    "val seed: Int = 60\n",
    "???\n",
    "\n",
    "// Count the number of element in each Dataframe\n",
    "val n_train: Long = ???\n",
    "val n_val: Long = ???\n",
    "val n_test: Long = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Training, validation, and test sets (2.2)\n",
    "assertEquals(n_train + n_val + n_test, 6724, \"unexpected Train, Val, Test data set size\")\n",
    "assertEquals(n_train, 5381, \"unexpected value for n_train\")\n",
    "assertEquals(n_val, 654, \"unexpected value for n_val\")\n",
    "assertEquals(n_test, 689, \"unexpected value for n_test\")\n",
    "assertEquals(train_df.storageLevel.useMemory, true, \"dataframe has to be cached\")\n",
    "assertEquals(val_df.storageLevel.useMemory, true, \"dataframe has to be cached\")\n",
    "assertEquals(test_df.storageLevel.useMemory, true, \"dataframe has to be cached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation matrix Plot\n",
    "\n",
    "Libraries MLlib and Spark ML provide multiple statistics tools such as some statistics tests or correlation matrixes. Let's plot the correlation matrix and detect which columns are correlated with the 'year release' label. \n",
    "- Wrap all the `ml_df` columns using a `VectorAssembler` object (See the doc).\n",
    "- After wrapping, compute the pearson correlation matrix and assign the result matrix to variable `pearsonCorr` (see the doc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace <FILL IN> with appropriate code\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.ml.stat.Correlation\n",
    "import org.apache.spark.ml.linalg.Matrix\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "\n",
    "val all_cols_names: Array[String] = ml_df.columns\n",
    "val vect_assembler: VectorAssembler = ???\n",
    "val all_wrapped_cols: DataFrame = vect_assembler.???\n",
    "val Row(pearsonCorr: Matrix) = Correlation.???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Training, validation, and test sets (3.3)\n",
    "assertEquals(pearsonCorr.getClass.toString, \"class org.apache.spark.ml.linalg.DenseMatrix\", \"pearsonCorr has to be type org.apache.spark.ml.linalg.DenseMatrix\")\n",
    "assertEquals((pearsonCorr.numCols,pearsonCorr.numRows), (13, 13), \"incorrect correlation matrix shape.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Printing your correlation matrix : \n",
    "println(\"Pearson correlation matrix:\\n\" + pearsonCorr.toString(13,125))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear regression with Spark ML\n",
    "\n",
    "This time, we will use linear regression with Spark ML instead of Spark MLlib. To achieve this task, you will be asked to wrap the features into an unique colummn, train a linear regression, make predictions and finally evaluate your rmse scores using an evaluator. Feel free to refer to the [Spark Documentation](https://spark.apache.org/docs/2.4.8/api/scala/index.html#org.apache.spark.ml.package) if needed.\n",
    "\n",
    "- Assign the list of all dataframe features columns names to variable `features_cols`.\n",
    "- Using a `VectorAssembler` object, wrap up all the features columns into a new column named 'all_features' (for train and test datasets). You have to set parameters `inputCols`and `outputCol`.\n",
    "- Using a `LinearRegression` object, train a machine learning model and use it to make prediction on test dataset. You have to set paramaters `featuresCol`, `labelCol` and `predictionCol`. Do not set any hypertuning parameter.\n",
    "- Use the model to make predictions on train, val and test dataset. Assign the resulting dataframe to variable `train_pred`, `val_pred` and `test_pred`.\n",
    "- Using a `RegressionEvaluator` object, compute the resulting RMSE scores. You have to set paramaters `predictionCol`, `labelCol` and `metricName`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "import org.apache.spark.ml.regression._\n",
    "import org.apache.spark.ml.evaluation._\n",
    "\n",
    "// Wrap the features into a unique column\n",
    "val features_cols: Array[String] = ???\n",
    "val vect_assembler: VectorAssembler = new VectorAssembler()\n",
    "  .???\n",
    "val train_df_wrapped: DataFrame = vect_assembler.???\n",
    "val val_df_wrapped: DataFrame = vect_assembler.???\n",
    "val test_df_wrapped: DataFrame = vect_assembler.???\n",
    "\n",
    "// Train and predict :\n",
    "val lr: LinearRegression = .???\n",
    "val model: LinearRegressionModel = .???\n",
    "val train_pred: DataFrame = model.???\n",
    "val val_pred: DataFrame = model.???\n",
    "val test_pred: DataFrame = model.???\n",
    "test_pred.show(5)\n",
    "\n",
    "// Evaluation : \n",
    "val evaluator: RegressionEvaluator = ???\n",
    "val rmse_train: Double = evaluator.???\n",
    "val rmse_val: Double = evaluator.???\n",
    "val rmse_test: Double = evaluator.???\n",
    "\n",
    "println(s\">>> Train RMSE Score : ${rmse_train}\")\n",
    "println(s\">>> Val RMSE Score : ${rmse_val}\")\n",
    "println(s\">>> Test RMSE Score : ${rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Linear Regression with Spark ML (3.4)\n",
    "assertEquals(features_cols.length, 12, \"features_cols length has to be 12.\")\n",
    "assertEquals(train_df_wrapped.columns.length, 14, \"Incorrect number of columns in train_df_wrapped.\")\n",
    "assertEquals(train_df_wrapped.columns.length, 14, \"Incorrect number of columns in test_df_wrapped.\")\n",
    "assertEquals(train_df_wrapped.columns.contains(\"all_features\"), true, \"Column 'all_features' does not exist in wrapped train dataset.\")\n",
    "assertEquals(test_df_wrapped.columns.contains(\"all_features\"), true, \"Column 'all_features' does not exist in wrapped test dataset.\")\n",
    "assertEquals((rmse_train*100.0).round/100.0, 15.53, \"Incorrect train RMSE Score.\")\n",
    "assertEquals((rmse_val*100.0).round/100.0, 16.30, \"Incorrect val RMSE Score.\")\n",
    "assertEquals((rmse_test*100.0).round/100.0, 15.32, \"Incorrect test RMSE Score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Add interactions between features (Order 2)\n",
    "\n",
    "So far, we've used the features as they were provided.  Now, we will add features that capture the two-way interactions between our existing features. For every set of features `x` and `y`, we will compute feature `x * y` (including when column x = column y).\n",
    "\n",
    "To achieve this task, tou will have to :\n",
    "- Create a UDF based on `compute_product` function that takes two feature columns as input and return the product of the two columns. Make sure that the resulting column will be named such as `feature_i_x_j` with `i` and `j` the features numbers.\n",
    "- Apply the UDF on train, val and test datasets using loops and `withColumn` method.\n",
    "\n",
    "_Hint_ : If needed, refer to the UDF Spark documentation or classroom lecture 3.\n",
    "\n",
    "_Hint_ : Because there are 12 features in dataset, it is expected to add 78 new columns to dataset.\n",
    "\n",
    "_Note_ : This task can also be achieved without UDF. However, here is a good chance to practice with UDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.UserDefinedFunction\n",
    "\n",
    "// Design the UDF :\n",
    "val compute_product = (x:Double, y:Double) => {\n",
    "      /*\n",
    "      Returns x * y\n",
    "      */\n",
    "      ???\n",
    "    }\n",
    "\n",
    "val my_udf: UserDefinedFunction = ???\n",
    "\n",
    "// Apply the UDF on train and test datasets\n",
    "val features_cols: Array[String] = ???\n",
    "val features_index: Seq[Int] = ???\n",
    "\n",
    "val index: Seq[(Int, Int)] = for {\n",
    "      i <- features_index\n",
    "      j <- features_index\n",
    "      if j >= i\n",
    "    } yield (i,j)\n",
    "\n",
    "val train_df_2 : DataFrame = index.foldLeft[DataFrame](train_df) {\n",
    "      ???\n",
    "    }.cache()\n",
    "\n",
    "val val_df_2 : DataFrame = index.foldLeft[DataFrame](val_df) {\n",
    "      ???\n",
    "    }.cache()\n",
    "\n",
    "val test_df_2 : DataFrame = index.foldLeft[DataFrame](test_df) {\n",
    "      ???\n",
    "    }.cache()\n",
    "            \n",
    "test_df_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST Add two-way interactions (3.5)\n",
    "assertEquals(train_df_2.columns.length, 91, \" Incorrect correct number of columns for train_df_2.\")\n",
    "assertEquals(val_df_2.columns.length, 91, \" Incorrect correct number of columns for val_df_2.\")\n",
    "assertEquals(test_df_2.columns.length, 91, \" Incorrect correct number of columns for test_df_2.\")\n",
    "assertEquals(train_df_2.dtypes.toList, List((\"year_release\", \"DoubleType\"), (\"feature_0\", \"DoubleType\"), (\"feature_1\", \"DoubleType\"), (\"feature_2\", \"DoubleType\"), (\"feature_3\", \"DoubleType\"), (\"feature_4\", \"DoubleType\"), (\"feature_5\", \"DoubleType\"), (\"feature_6\", \"DoubleType\"), (\"feature_7\", \"DoubleType\"), (\"feature_8\", \"DoubleType\"), (\"feature_9\", \"DoubleType\"), (\"feature_10\", \"DoubleType\"), (\"feature_11\", \"DoubleType\"), (\"feature_0_x_0\", \"DoubleType\"), (\"feature_0_x_1\", \"DoubleType\"), (\"feature_0_x_2\", \"DoubleType\"), (\"feature_0_x_3\", \"DoubleType\"), (\"feature_0_x_4\", \"DoubleType\"), (\"feature_0_x_5\", \"DoubleType\"), (\"feature_0_x_6\", \"DoubleType\"), (\"feature_0_x_7\", \"DoubleType\"), (\"feature_0_x_8\", \"DoubleType\"), (\"feature_0_x_9\", \"DoubleType\"), (\"feature_0_x_10\", \"DoubleType\"), (\"feature_0_x_11\", \"DoubleType\"), (\"feature_1_x_1\", \"DoubleType\"), (\"feature_1_x_2\", \"DoubleType\"), (\"feature_1_x_3\", \"DoubleType\"), (\"feature_1_x_4\", \"DoubleType\"), (\"feature_1_x_5\", \"DoubleType\"), (\"feature_1_x_6\", \"DoubleType\"), (\"feature_1_x_7\", \"DoubleType\"), (\"feature_1_x_8\", \"DoubleType\"), (\"feature_1_x_9\", \"DoubleType\"), (\"feature_1_x_10\", \"DoubleType\"), (\"feature_1_x_11\", \"DoubleType\"), (\"feature_2_x_2\", \"DoubleType\"), (\"feature_2_x_3\", \"DoubleType\"), (\"feature_2_x_4\", \"DoubleType\"), (\"feature_2_x_5\", \"DoubleType\"), (\"feature_2_x_6\", \"DoubleType\"), (\"feature_2_x_7\", \"DoubleType\"), (\"feature_2_x_8\", \"DoubleType\"), (\"feature_2_x_9\", \"DoubleType\"), (\"feature_2_x_10\", \"DoubleType\"), (\"feature_2_x_11\", \"DoubleType\"), (\"feature_3_x_3\", \"DoubleType\"), (\"feature_3_x_4\", \"DoubleType\"), (\"feature_3_x_5\", \"DoubleType\"), (\"feature_3_x_6\", \"DoubleType\"), (\"feature_3_x_7\", \"DoubleType\"), (\"feature_3_x_8\", \"DoubleType\"), (\"feature_3_x_9\", \"DoubleType\"), (\"feature_3_x_10\", \"DoubleType\"), (\"feature_3_x_11\", \"DoubleType\"), (\"feature_4_x_4\", \"DoubleType\"), (\"feature_4_x_5\", \"DoubleType\"), (\"feature_4_x_6\", \"DoubleType\"), (\"feature_4_x_7\", \"DoubleType\"), (\"feature_4_x_8\", \"DoubleType\"), (\"feature_4_x_9\", \"DoubleType\"), (\"feature_4_x_10\", \"DoubleType\"), (\"feature_4_x_11\", \"DoubleType\"), (\"feature_5_x_5\", \"DoubleType\"), (\"feature_5_x_6\", \"DoubleType\"), (\"feature_5_x_7\", \"DoubleType\"), (\"feature_5_x_8\", \"DoubleType\"), (\"feature_5_x_9\", \"DoubleType\"), (\"feature_5_x_10\", \"DoubleType\"), (\"feature_5_x_11\", \"DoubleType\"), (\"feature_6_x_6\", \"DoubleType\"), (\"feature_6_x_7\", \"DoubleType\"), (\"feature_6_x_8\", \"DoubleType\"), (\"feature_6_x_9\", \"DoubleType\"), (\"feature_6_x_10\", \"DoubleType\"), (\"feature_6_x_11\", \"DoubleType\"), (\"feature_7_x_7\", \"DoubleType\"), (\"feature_7_x_8\", \"DoubleType\"), (\"feature_7_x_9\", \"DoubleType\"), (\"feature_7_x_10\", \"DoubleType\"), (\"feature_7_x_11\", \"DoubleType\"), (\"feature_8_x_8\", \"DoubleType\"), (\"feature_8_x_9\", \"DoubleType\"), (\"feature_8_x_10\", \"DoubleType\"), (\"feature_8_x_11\", \"DoubleType\"), (\"feature_9_x_9\", \"DoubleType\"), (\"feature_9_x_10\", \"DoubleType\"), (\"feature_9_x_11\", \"DoubleType\"), (\"feature_10_x_10\", \"DoubleType\"), (\"feature_10_x_11\", \"DoubleType\"), (\"feature_11_x_11\", \"DoubleType\")), \"incorrect columns names or casting.\")\n",
    "assertEquals(val_df_2.dtypes.toList, List((\"year_release\", \"DoubleType\"), (\"feature_0\", \"DoubleType\"), (\"feature_1\", \"DoubleType\"), (\"feature_2\", \"DoubleType\"), (\"feature_3\", \"DoubleType\"), (\"feature_4\", \"DoubleType\"), (\"feature_5\", \"DoubleType\"), (\"feature_6\", \"DoubleType\"), (\"feature_7\", \"DoubleType\"), (\"feature_8\", \"DoubleType\"), (\"feature_9\", \"DoubleType\"), (\"feature_10\", \"DoubleType\"), (\"feature_11\", \"DoubleType\"), (\"feature_0_x_0\", \"DoubleType\"), (\"feature_0_x_1\", \"DoubleType\"), (\"feature_0_x_2\", \"DoubleType\"), (\"feature_0_x_3\", \"DoubleType\"), (\"feature_0_x_4\", \"DoubleType\"), (\"feature_0_x_5\", \"DoubleType\"), (\"feature_0_x_6\", \"DoubleType\"), (\"feature_0_x_7\", \"DoubleType\"), (\"feature_0_x_8\", \"DoubleType\"), (\"feature_0_x_9\", \"DoubleType\"), (\"feature_0_x_10\", \"DoubleType\"), (\"feature_0_x_11\", \"DoubleType\"), (\"feature_1_x_1\", \"DoubleType\"), (\"feature_1_x_2\", \"DoubleType\"), (\"feature_1_x_3\", \"DoubleType\"), (\"feature_1_x_4\", \"DoubleType\"), (\"feature_1_x_5\", \"DoubleType\"), (\"feature_1_x_6\", \"DoubleType\"), (\"feature_1_x_7\", \"DoubleType\"), (\"feature_1_x_8\", \"DoubleType\"), (\"feature_1_x_9\", \"DoubleType\"), (\"feature_1_x_10\", \"DoubleType\"), (\"feature_1_x_11\", \"DoubleType\"), (\"feature_2_x_2\", \"DoubleType\"), (\"feature_2_x_3\", \"DoubleType\"), (\"feature_2_x_4\", \"DoubleType\"), (\"feature_2_x_5\", \"DoubleType\"), (\"feature_2_x_6\", \"DoubleType\"), (\"feature_2_x_7\", \"DoubleType\"), (\"feature_2_x_8\", \"DoubleType\"), (\"feature_2_x_9\", \"DoubleType\"), (\"feature_2_x_10\", \"DoubleType\"), (\"feature_2_x_11\", \"DoubleType\"), (\"feature_3_x_3\", \"DoubleType\"), (\"feature_3_x_4\", \"DoubleType\"), (\"feature_3_x_5\", \"DoubleType\"), (\"feature_3_x_6\", \"DoubleType\"), (\"feature_3_x_7\", \"DoubleType\"), (\"feature_3_x_8\", \"DoubleType\"), (\"feature_3_x_9\", \"DoubleType\"), (\"feature_3_x_10\", \"DoubleType\"), (\"feature_3_x_11\", \"DoubleType\"), (\"feature_4_x_4\", \"DoubleType\"), (\"feature_4_x_5\", \"DoubleType\"), (\"feature_4_x_6\", \"DoubleType\"), (\"feature_4_x_7\", \"DoubleType\"), (\"feature_4_x_8\", \"DoubleType\"), (\"feature_4_x_9\", \"DoubleType\"), (\"feature_4_x_10\", \"DoubleType\"), (\"feature_4_x_11\", \"DoubleType\"), (\"feature_5_x_5\", \"DoubleType\"), (\"feature_5_x_6\", \"DoubleType\"), (\"feature_5_x_7\", \"DoubleType\"), (\"feature_5_x_8\", \"DoubleType\"), (\"feature_5_x_9\", \"DoubleType\"), (\"feature_5_x_10\", \"DoubleType\"), (\"feature_5_x_11\", \"DoubleType\"), (\"feature_6_x_6\", \"DoubleType\"), (\"feature_6_x_7\", \"DoubleType\"), (\"feature_6_x_8\", \"DoubleType\"), (\"feature_6_x_9\", \"DoubleType\"), (\"feature_6_x_10\", \"DoubleType\"), (\"feature_6_x_11\", \"DoubleType\"), (\"feature_7_x_7\", \"DoubleType\"), (\"feature_7_x_8\", \"DoubleType\"), (\"feature_7_x_9\", \"DoubleType\"), (\"feature_7_x_10\", \"DoubleType\"), (\"feature_7_x_11\", \"DoubleType\"), (\"feature_8_x_8\", \"DoubleType\"), (\"feature_8_x_9\", \"DoubleType\"), (\"feature_8_x_10\", \"DoubleType\"), (\"feature_8_x_11\", \"DoubleType\"), (\"feature_9_x_9\", \"DoubleType\"), (\"feature_9_x_10\", \"DoubleType\"), (\"feature_9_x_11\", \"DoubleType\"), (\"feature_10_x_10\", \"DoubleType\"), (\"feature_10_x_11\", \"DoubleType\"), (\"feature_11_x_11\", \"DoubleType\")), \"incorrect columns names or casting.\")\n",
    "assertEquals(test_df_2.dtypes.toList, List((\"year_release\", \"DoubleType\"), (\"feature_0\", \"DoubleType\"), (\"feature_1\", \"DoubleType\"), (\"feature_2\", \"DoubleType\"), (\"feature_3\", \"DoubleType\"), (\"feature_4\", \"DoubleType\"), (\"feature_5\", \"DoubleType\"), (\"feature_6\", \"DoubleType\"), (\"feature_7\", \"DoubleType\"), (\"feature_8\", \"DoubleType\"), (\"feature_9\", \"DoubleType\"), (\"feature_10\", \"DoubleType\"), (\"feature_11\", \"DoubleType\"), (\"feature_0_x_0\", \"DoubleType\"), (\"feature_0_x_1\", \"DoubleType\"), (\"feature_0_x_2\", \"DoubleType\"), (\"feature_0_x_3\", \"DoubleType\"), (\"feature_0_x_4\", \"DoubleType\"), (\"feature_0_x_5\", \"DoubleType\"), (\"feature_0_x_6\", \"DoubleType\"), (\"feature_0_x_7\", \"DoubleType\"), (\"feature_0_x_8\", \"DoubleType\"), (\"feature_0_x_9\", \"DoubleType\"), (\"feature_0_x_10\", \"DoubleType\"), (\"feature_0_x_11\", \"DoubleType\"), (\"feature_1_x_1\", \"DoubleType\"), (\"feature_1_x_2\", \"DoubleType\"), (\"feature_1_x_3\", \"DoubleType\"), (\"feature_1_x_4\", \"DoubleType\"), (\"feature_1_x_5\", \"DoubleType\"), (\"feature_1_x_6\", \"DoubleType\"), (\"feature_1_x_7\", \"DoubleType\"), (\"feature_1_x_8\", \"DoubleType\"), (\"feature_1_x_9\", \"DoubleType\"), (\"feature_1_x_10\", \"DoubleType\"), (\"feature_1_x_11\", \"DoubleType\"), (\"feature_2_x_2\", \"DoubleType\"), (\"feature_2_x_3\", \"DoubleType\"), (\"feature_2_x_4\", \"DoubleType\"), (\"feature_2_x_5\", \"DoubleType\"), (\"feature_2_x_6\", \"DoubleType\"), (\"feature_2_x_7\", \"DoubleType\"), (\"feature_2_x_8\", \"DoubleType\"), (\"feature_2_x_9\", \"DoubleType\"), (\"feature_2_x_10\", \"DoubleType\"), (\"feature_2_x_11\", \"DoubleType\"), (\"feature_3_x_3\", \"DoubleType\"), (\"feature_3_x_4\", \"DoubleType\"), (\"feature_3_x_5\", \"DoubleType\"), (\"feature_3_x_6\", \"DoubleType\"), (\"feature_3_x_7\", \"DoubleType\"), (\"feature_3_x_8\", \"DoubleType\"), (\"feature_3_x_9\", \"DoubleType\"), (\"feature_3_x_10\", \"DoubleType\"), (\"feature_3_x_11\", \"DoubleType\"), (\"feature_4_x_4\", \"DoubleType\"), (\"feature_4_x_5\", \"DoubleType\"), (\"feature_4_x_6\", \"DoubleType\"), (\"feature_4_x_7\", \"DoubleType\"), (\"feature_4_x_8\", \"DoubleType\"), (\"feature_4_x_9\", \"DoubleType\"), (\"feature_4_x_10\", \"DoubleType\"), (\"feature_4_x_11\", \"DoubleType\"), (\"feature_5_x_5\", \"DoubleType\"), (\"feature_5_x_6\", \"DoubleType\"), (\"feature_5_x_7\", \"DoubleType\"), (\"feature_5_x_8\", \"DoubleType\"), (\"feature_5_x_9\", \"DoubleType\"), (\"feature_5_x_10\", \"DoubleType\"), (\"feature_5_x_11\", \"DoubleType\"), (\"feature_6_x_6\", \"DoubleType\"), (\"feature_6_x_7\", \"DoubleType\"), (\"feature_6_x_8\", \"DoubleType\"), (\"feature_6_x_9\", \"DoubleType\"), (\"feature_6_x_10\", \"DoubleType\"), (\"feature_6_x_11\", \"DoubleType\"), (\"feature_7_x_7\", \"DoubleType\"), (\"feature_7_x_8\", \"DoubleType\"), (\"feature_7_x_9\", \"DoubleType\"), (\"feature_7_x_10\", \"DoubleType\"), (\"feature_7_x_11\", \"DoubleType\"), (\"feature_8_x_8\", \"DoubleType\"), (\"feature_8_x_9\", \"DoubleType\"), (\"feature_8_x_10\", \"DoubleType\"), (\"feature_8_x_11\", \"DoubleType\"), (\"feature_9_x_9\", \"DoubleType\"), (\"feature_9_x_10\", \"DoubleType\"), (\"feature_9_x_11\", \"DoubleType\"), (\"feature_10_x_10\", \"DoubleType\"), (\"feature_10_x_11\", \"DoubleType\"), (\"feature_11_x_11\", \"DoubleType\")), \"incorrect columns names or casting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Linear regression model with features interactions (order 2)\n",
    "\n",
    "Using the previously computed new 78 columns, we are now able to catch interaction between variable in order to build a more robust linear regression model. As for task 3.4, train this new machine learning algorithm and compute the new RMSE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "\n",
    "// Wrap the features into a unique column\n",
    "val features_cols: Array[String] = ???\n",
    "val vect_assembler: VectorAssembler = new VectorAssembler()\n",
    "    .???\n",
    "val train_df_wrapped: DataFrame = vect_assembler.???\n",
    "val val_df_wrapped: DataFrame = vect_assembler.???\n",
    "val test_df_wrapped: DataFrame = vect_assembler.???\n",
    "\n",
    "// Train and predict :\n",
    "val lr: LinearRegression = ???\n",
    "val model: LinearRegressionModel = lr.???\n",
    "val train_pred: DataFrame = model.???\n",
    "val val_pred: DataFrame = model.???\n",
    "val test_pred: DataFrame = model.???\n",
    "test_pred.show(5)\n",
    "\n",
    "// Evaluation : \n",
    "val evaluator: RegressionEvaluator = ???\n",
    "val rmse_train: Double = evaluator.???\n",
    "val rmse_val: Double = evaluator.???\n",
    "val rmse_test: Double = evaluator.???\n",
    "\n",
    "println(s\">>> Train RMSE Score : ${rmse_train}\")\n",
    "println(s\">>> Val RMSE Score : ${rmse_val}\")\n",
    "println(s\">>> Test RMSE Score : ${rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TEST New Linear Regression with features interactions (3.6)\n",
    "assertEquals(features_cols.length, 90, \"features_cols length has to be 90.\")\n",
    "assertEquals(train_df_wrapped.columns.length, 92, \"Incorrect number of columns in train_df_wrapped.\")\n",
    "assertEquals(val_df_wrapped.columns.length, 92, \"Incorrect number of columns in test_df_wrapped.\")\n",
    "assertEquals(test_df_wrapped.columns.length, 92, \"Incorrect number of columns in test_df_wrapped.\")\n",
    "assertEquals(train_df_wrapped.columns.contains(\"all_features\"), true, \"Column 'all_features' does not exist in wrapped train dataset.\")\n",
    "assertEquals(test_df_wrapped.columns.contains(\"all_features\"), true, \"Column 'all_features' does not exist in wrapped test dataset.\")\n",
    "assertEquals((rmse_train*100.0).round/100.0, 14.50, \"Incorrect train RMSE Score.\")\n",
    "assertEquals((rmse_val*100.0).round/100.0, 15.34, \"Incorrect val RMSE Score.\")\n",
    "assertEquals((rmse_test*100.0).round/100.0, 14.52, \"Incorrect test RMSE Score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. An example of extensive hypertuning cross-validator\n",
    "\n",
    "Here, we build a simple a simple example of a grid cross-validator in order to find the best regularization hyperparameters (`regParam` and `elasticNetParam`) for our regression model. According to our previous rmse scores on train, val and test datasets (which are very close to each other),  it seems that our linear model is currently under-fitting. Thus, the regularization tuning will not necessarily result in an improvement on test dataset. However, in the following part 3, you will interest in features interaction with order 3 or tree-based machine learning algorithms. In these cases, hypertuning cross-validator would be really helpful.\n",
    "\n",
    "We use 2 grids of parameters : <br>\n",
    "ElasticNetParam = [0.0, 0.35, 0.65, 1.0] <br>\n",
    "RegParam = [0.0, 0.001, 0.01, 1.0]\n",
    "\n",
    "_Note_ : Don't forget to cache your datasets in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.tuning._\n",
    "import org.apache.spark.ml.param._\n",
    "\n",
    "// Preprocessing the Datasets\n",
    "val train_val_df_2: DataFrame = train_df_2.union(val_df_2).cache()\n",
    "val features_cols: Array[String] = train_val_df_2.columns.filter(col => col != \"year_release\")\n",
    "val vect_assembler: VectorAssembler = new VectorAssembler()\n",
    "    .setInputCols(features_cols)\n",
    "    .setOutputCol(\"all_features\")\n",
    "val train_df_wrapped: DataFrame = vect_assembler.transform(train_val_df_2)\n",
    "val test_df_wrapped: DataFrame = vect_assembler.transform(test_df_2)\n",
    "\n",
    "// Define the Grid\n",
    "val lr: LinearRegression = new LinearRegression()\n",
    "val grid: Array[ParamMap] = new ParamGridBuilder().baseOn({lr.labelCol -> \"year_release\"})\n",
    "  .baseOn({lr.featuresCol -> \"all_features\"})\n",
    "  .baseOn({lr.predictionCol -> \"prediction\"})\n",
    "  .addGrid(lr.elasticNetParam, ???)\n",
    "  .addGrid(lr.regParam, ???)\n",
    "  .build()\n",
    "        \n",
    "\n",
    "val evaluator: RegressionEvaluator = ???\n",
    "val cv: CrossValidator = new CrossValidator()\n",
    "    .setEstimator(lr)\n",
    "    .setEstimatorParamMaps(grid)\n",
    "    .setEvaluator(evaluator)\n",
    "    .setNumFolds(5) // use 3+ folds in practice\n",
    "\n",
    "// Run cross-validation, and choose the best set of parameters.\n",
    "val cvModel: CrossValidatorModel = cv.fit(train_df_wrapped.cache())\n",
    "\n",
    "// Make predictions on test dataset. cvModel uses the best model found.\n",
    "val rmse_train: Double = evaluator.evaluate(cvModel.transform(train_df_wrapped))\n",
    "val rmse_test: Double = evaluator.evaluate(cvModel.transform(test_df_wrapped))\n",
    "println(s\">>> Train RMSE Score : ${rmse_train}\")\n",
    "println(s\">>> Test RMSE Score : ${rmse_test}\")\n",
    "\n",
    "// Info display\n",
    "println(\"\\n===== Hypertuning cross validation results : =====\")\n",
    "cvModel.getEstimatorParamMaps.zip(cvModel.avgMetrics)\n",
    "  .foreach(x => {\n",
    "    println(s\"Model ${cvModel.getEstimatorParamMaps.indexOf(x._1)} :\" )\n",
    "    println(s\"Params : ${x._1.toSeq.map(y => (y.param.name,y.value)).mkString(\",\")}\")\n",
    "    println(s\"Average validation score : ${x._2}\\n\")\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : Beat the benchmark\n",
    "\n",
    "So far we have tried multiple linear regression models with Spark MLLib. Our best model reaches a test RMSE score about `14.55`. Let us now use more powerful models such as tree-based ones ! Can you beat the benchmark `14.25`?\n",
    "\n",
    "Some ideas :\n",
    "- You can try one or several algorithms including `DecisionTreeRegressor`, `RandomForestRegressor`,  `GBTRegressor`(gradient boosting). See the spark.ml documentation for more information on algorithms settings [Spark ML Documentation](https://spark.apache.org/docs/2.4.8/api/scala/index.html#org.apache.spark.ml.package)\n",
    "- You can also try hypertuning cross-validator in order to reach the best test score.\n",
    "\n",
    "Notes :\n",
    "- Because tree-based technics are non-linear algorithms, you should use the original dataframes with 12 features. Using `train_df_2` will massively increase computing time with a increased risk of overfitting.\n",
    "- For `RandomForestRegressor` and  `GBTRegressor`, be careful with the number of trees. Because you are running algorithm in a Spark local environment, you don't have a lot of computing resources.\n",
    "- Make sure to cache your dataframes for better performances.\n",
    "- Hypertuning cross-validator is weel suited for decision tree but not for `RandomForest` and `GBT`. Because you are running algorithm in a Spark local environment, you don't have enough computing resources to afford heavy grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tree Based Technics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: Replace ??? with appropriate code\n",
    "// Look for LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor and RegressionEvaluator\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vegas.layered(\"Tree Based techniques\", width = 600, height = 300).\n",
    "  withDataFrame(test_pred).\n",
    "  withLayers(\n",
    "    Layer().\n",
    "      mark(Line).\n",
    "      encodeX(\"year_release\", Quant, axis=Axis(title=\"Predicted\")).\n",
    "      encodeY(\"year_release\", Quant, axis=Axis(title=\"Actual\")),\n",
    "    Layer().\n",
    "      mark(Point).\n",
    "      encodeX(\"prediction\", Quant).\n",
    "      encodeY(\"year_release\", Quant)\n",
    "  ).\n",
    "  show\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Scala (2.11)",
   "language": "scala",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.11.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "bibliography.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "3",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
